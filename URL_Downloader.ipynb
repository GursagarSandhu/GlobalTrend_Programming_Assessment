{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL downloader:\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "class URLDownloader:\n",
    "    def __init__(self):\n",
    "        self.urls = []\n",
    "        self.results = {}\n",
    "\n",
    "    def download_and_parse(self, retries=3, delay=2):\n",
    "        for url in self.urls:\n",
    "            for attempt in range(retries):\n",
    "                try:\n",
    "                    response = requests.get(url)\n",
    "                    response.raise_for_status()\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                    self.results[url] = soup  \n",
    "                    break  \n",
    "                except requests.exceptions.HTTPError as http_err:\n",
    "                    error_message = f\"HTTP error occurred: {http_err}\"\n",
    "                except requests.exceptions.ConnectionError as conn_err:\n",
    "                    error_message = f\"Connection error occurred: {conn_err}\"\n",
    "                except requests.exceptions.Timeout as timeout_err:\n",
    "                    error_message = f\"Timeout error occurred: {timeout_err}\"\n",
    "                except requests.exceptions.RequestException as req_err:\n",
    "                    error_message = f\"General error occurred: {req_err}\"\n",
    "\n",
    "                if attempt < retries - 1:  \n",
    "                    sleep(delay)\n",
    "                else:  \n",
    "                    self.results[url] = error_message\n",
    "\n",
    "    def get_user_urls(self):\n",
    "        try:\n",
    "            num_urls = int(input(\"Enter the number of URLs you want to add: \"))\n",
    "            if num_urls <= 0:\n",
    "                print(\"Please enter a positive number.\")\n",
    "                return\n",
    "            \n",
    "            print(f\"Enter {num_urls} URLs (one per line):\")\n",
    "            for _ in range(num_urls):\n",
    "                url = input().strip()\n",
    "                if url:\n",
    "                    self.urls.append(url)\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "    def print_results(self):\n",
    "        print(\"\\nResults:\")\n",
    "        for url, result in self.results.items():\n",
    "            if isinstance(result, BeautifulSoup):\n",
    "                title = result.title.string if result.title else \"No title found\"\n",
    "                print(f\"URL: {url}\\nTitle: {title}\\n\")\n",
    "            else:\n",
    "                print(f\"URL: {url}\\nError: {result}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    downloader = URLDownloader()\n",
    "    print(\"Enter URLs to download:\")\n",
    "    downloader.get_user_urls()\n",
    "\n",
    "    if downloader.urls:\n",
    "        downloader.download_and_parse()\n",
    "        downloader.print_results()\n",
    "    else:\n",
    "        print(\"No URLs entered.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
